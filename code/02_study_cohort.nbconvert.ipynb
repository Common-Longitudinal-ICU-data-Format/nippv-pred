{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:29.935915Z",
     "iopub.status.busy": "2026-02-19T15:42:29.935711Z",
     "iopub.status.idle": "2026-02-19T15:42:29.944433Z",
     "shell.execute_reply": "2026-02-19T15:42:29.943709Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load site config\n",
    "config_path = os.path.join('..', 'config.json')\n",
    "if not os.path.exists(config_path):\n",
    "    config_path = os.path.join('..', 'clif_config.json')\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "SITE = config.get('site', 'unknown')\n",
    "\n",
    "#Create structure for consort data information\n",
    "consort = { \n",
    "    #initial data information\n",
    "    \"total_rows_loaded\": None,\n",
    "    \"total_admissions\": None,\n",
    "\n",
    "    #inclusion/exclusion criteria\n",
    "    \"total_nippv_6h\": None,\n",
    "    \"total_fio2_60\": None,\n",
    "    \"total_pco2_45\": None,\n",
    "    \"total_ph_7.35\": None,\n",
    "\n",
    "    #cohort size and failures BEFORE dropping missing data\n",
    "    \"patients_pre_missing\": None,\n",
    "    \"failures_pre_missing\": None,\n",
    "    \"imv_fail_pre_missing\": None,\n",
    "    \"death_fail_pre_missing\": None,\n",
    "    \"both_fail_pre_missing\": None,\n",
    "\n",
    "    #cohort size and failures AFTER dropping missing data\n",
    "    \"patients_post_missing\": None,\n",
    "    \"failures_post_missing\": None,\n",
    "    \"imv_fail_post_missing\": None,\n",
    "    \"death_fail_post_missing\": None,\n",
    "    \"both_fail_post_missing\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:29.947176Z",
     "iopub.status.busy": "2026-02-19T15:42:29.946990Z",
     "iopub.status.idle": "2026-02-19T15:42:30.492787Z",
     "shell.execute_reply": "2026-02-19T15:42:30.492332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows loaded: 1825104\n",
      "Total ICU NIPPV Admissions: 5468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import dataset\n",
    "df = pd.read_parquet('../output/study_cohort_NIPPV_&_ICU.parquet')\n",
    "\n",
    "print(f'Total rows loaded: {len(df)}')\n",
    "consort[\"total_rows_loaded\"] = len(df)\n",
    "\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total ICU NIPPV Admissions: {admissions}')\n",
    "consort[\"total_admissions\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:30.507252Z",
     "iopub.status.busy": "2026-02-19T15:42:30.507108Z",
     "iopub.status.idle": "2026-02-19T15:42:30.904686Z",
     "shell.execute_reply": "2026-02-19T15:42:30.904259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to standard pandas datetime\n",
    "df['event_time'] = pd.to_datetime(df['event_time'], utc = True)\n",
    "df['admission_dttm'] = pd.to_datetime(df['admission_dttm'], utc = True)\n",
    "\n",
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:30.905905Z",
     "iopub.status.busy": "2026-02-19T15:42:30.905839Z",
     "iopub.status.idle": "2026-02-19T15:42:32.065058Z",
     "shell.execute_reply": "2026-02-19T15:42:32.064725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows loaded: 538587\n",
      "Total NIPPV < 6 hrs: 2553\n"
     ]
    }
   ],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "vital_sign_cols = ['heart_rate', 'respiratory_rate', 'spo2', 'sbp', 'temp_c']\n",
    "\n",
    "# Identify First Vital Sign\n",
    "vitals = df[df[vital_sign_cols].notna().any(axis=1)]\n",
    "vitals = vitals.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "first_vital = (\n",
    "    vitals.groupby('hospitalization_id')\n",
    "          .first()\n",
    "          .reset_index()[['hospitalization_id', 'event_time']]\n",
    "          .rename(columns={'event_time': 'first_vital_time'})\n",
    ")\n",
    "\n",
    "# Identify First NIPPV Instance\n",
    "nippv = df[df['device_category'] == 'NIPPV']\n",
    "nippv = nippv.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "first_nippv = (\n",
    "    nippv.groupby('hospitalization_id')\n",
    "         .first()\n",
    "         .reset_index()[['hospitalization_id', 'event_time']]\n",
    "         .rename(columns={'event_time': 'first_nippv_time'})\n",
    ")\n",
    "\n",
    "# Merge First NIPPV Instance with First Vital and Calculate Time differene (time_to_NIPPV)\n",
    "merged = first_vital.merge(first_nippv, on='hospitalization_id')\n",
    "merged['time_to_NIPPV'] = (\n",
    "    merged['first_nippv_time'] - merged['first_vital_time']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Filter dataframe to contain only hospitalizations where NIPPV occured within 6 hours of first vital sign\n",
    "eligible_ids = merged[merged['time_to_NIPPV'] <= 6]['hospitalization_id']\n",
    "df = df[df['hospitalization_id'].isin(eligible_ids)]\n",
    "\n",
    "# Merge time_to_NIPPV and first_vital_time back into main dataframe\n",
    "df = df.merge(\n",
    "    merged[['hospitalization_id', 'time_to_NIPPV']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "df = df.merge(\n",
    "    first_vital[['hospitalization_id', 'first_vital_time']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Print total rows and admissions\n",
    "print(f'Total rows loaded: {len(df)}')\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total NIPPV < 6 hrs: {admissions}')\n",
    "consort[\"total_nippv_6h\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.066182Z",
     "iopub.status.busy": "2026-02-19T15:42:32.066113Z",
     "iopub.status.idle": "2026-02-19T15:42:32.288854Z",
     "shell.execute_reply": "2026-02-19T15:42:32.288469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows loaded: 216393\n",
      "Total NIPPV < 6 hrs: 2553\n"
     ]
    }
   ],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Calculate nippv_start_time\n",
    "df['nippv_start_time'] = (\n",
    "    df['first_vital_time'] + pd.to_timedelta(df['time_to_NIPPV'], unit='h')\n",
    ")\n",
    "\n",
    "#Calculate time_since_nippv\n",
    "df['time_since_nippv'] = (\n",
    "    df['event_time'] - df['nippv_start_time']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "#Filter to rows w/in 48 hours of NIPPV start\n",
    "df = df[df['time_since_nippv'] <= 48]\n",
    "\n",
    "# Print total rows and admissions\n",
    "print(f'Total rows loaded: {len(df)}')\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total NIPPV < 6 hrs: {admissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.289886Z",
     "iopub.status.busy": "2026-02-19T15:42:32.289822Z",
     "iopub.status.idle": "2026-02-19T15:42:32.373301Z",
     "shell.execute_reply": "2026-02-19T15:42:32.372962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NIPPV < 6 hrs & fio2_set <= 60: 1056\n"
     ]
    }
   ],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Filter to 1 hour after NIPPV initiation\n",
    "df_PreNIPPV = df[df['event_time'] < df['nippv_start_time'] + pd.Timedelta(hours=1)]\n",
    "\n",
    "# Get the median fio2_set for each hospitalization_id prior to NIPPV initiation\n",
    "median_fio2_PreNIPPV = df_PreNIPPV.groupby('hospitalization_id')['fio2_set'].median().reset_index()\n",
    "\n",
    "# Identify eligible hospitalizations where max fio2_set <= .6 prior to NIPPV initiation\n",
    "eligible_fio2 = median_fio2_PreNIPPV[median_fio2_PreNIPPV['fio2_set'] <= .6]['hospitalization_id']\n",
    "\n",
    "# Filter the df to keep only eligible fio2 hospitalizations\n",
    "df = df[df['hospitalization_id'].isin(eligible_fio2)].reset_index(drop=True)\n",
    "\n",
    "#Print total admissions\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total NIPPV < 6 hrs & fio2_set <= 60: {admissions}')\n",
    "consort[\"total_fio2_60\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.374291Z",
     "iopub.status.busy": "2026-02-19T15:42:32.374229Z",
     "iopub.status.idle": "2026-02-19T15:42:32.404405Z",
     "shell.execute_reply": "2026-02-19T15:42:32.404011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NIPPV < 6 hrs & fio2_set <= 60 & pco2 >= 45: 458\n"
     ]
    }
   ],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Update df_PreNIPPV with only filtered admissions\n",
    "df_PreNIPPV = df[df['event_time'] < df['nippv_start_time'] + pd.Timedelta(hours=1)]\n",
    "\n",
    "# Get median pco2_arterial and pco2_venous prior to NIPPV initiation for each hospitalization_id\n",
    "median_pco2_arterial = df_PreNIPPV.groupby('hospitalization_id')['pco2_arterial'].median()\n",
    "median_pco2_venous = df_PreNIPPV.groupby('hospitalization_id')['pco2_venous'].median()\n",
    "\n",
    "# Combine median_pco2_arterial and median_pco2_venous into one dataframe\n",
    "median_pco2 = pd.DataFrame({\n",
    "    'pco2_arterial': median_pco2_arterial,\n",
    "    'pco2_venous': median_pco2_venous\n",
    "}).reset_index()\n",
    "\n",
    "# Filter rows where median_pco2_arterial or median_pco2_venous >= 45\n",
    "eligible_pco2 = median_pco2[\n",
    "    (median_pco2['pco2_arterial'] >= 45) | (median_pco2['pco2_venous'] >= 45)\n",
    "]['hospitalization_id']\n",
    "\n",
    "# Filter the df to keep only eligible pco2 hospitalizations\n",
    "df = df[df['hospitalization_id'].isin(eligible_pco2)].reset_index(drop=True)\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total admissions\n",
    "print(f'Total NIPPV < 6 hrs & fio2_set <= 60 & pco2 >= 45: {len(eligible_pco2)}')\n",
    "consort[\"total_pco2_45\"] = len(eligible_pco2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.405404Z",
     "iopub.status.busy": "2026-02-19T15:42:32.405339Z",
     "iopub.status.idle": "2026-02-19T15:42:32.422136Z",
     "shell.execute_reply": "2026-02-19T15:42:32.421827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NIPPV < 6 hrs & fio2_set <= 60 & pco2 >= 45 & ph <= 7.35: 364\n"
     ]
    }
   ],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Update df_PreNIPPV with only filtered admissions\n",
    "df_PreNIPPV = df[df['event_time'] < df['nippv_start_time'] + pd.Timedelta(hours=1)]\n",
    "\n",
    "# Get median ph_arterial and ph_venous prior to NIPPV initiation for each hospitalization_id\n",
    "median_ph_arterial = df_PreNIPPV.groupby('hospitalization_id')['ph_arterial'].median()\n",
    "median_ph_venous = df_PreNIPPV.groupby('hospitalization_id')['ph_venous'].median()\n",
    "\n",
    "# Combine median_ph_arterial and median_ph_venous into one dataframe\n",
    "median_ph = pd.DataFrame({\n",
    "    'ph_arterial': median_ph_arterial,\n",
    "    'ph_venous': median_ph_venous\n",
    "}).reset_index()\n",
    "\n",
    "# Filter to rows where median_ph_arterial or median_ph_venous <= 7.35\n",
    "eligible_ph = median_ph[\n",
    "    (median_ph['ph_arterial'] <= 7.35) | (median_ph['ph_venous'] <= 7.35)\n",
    "]['hospitalization_id']\n",
    "\n",
    "# Filter the df to keep only eligible ph hospitalizations\n",
    "df = df[df['hospitalization_id'].isin(eligible_ph)].reset_index(drop=True)\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total admissions\n",
    "print(f'Total NIPPV < 6 hrs & fio2_set <= 60 & pco2 >= 45 & ph <= 7.35: {len(eligible_ph)}')\n",
    "consort[\"total_ph_7.35\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.423084Z",
     "iopub.status.busy": "2026-02-19T15:42:32.423030Z",
     "iopub.status.idle": "2026-02-19T15:42:32.443083Z",
     "shell.execute_reply": "2026-02-19T15:42:32.442714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deaths time-bounded to 48h using discharge_dttm\n",
      "  Late deaths excluded (>48h): 39\n",
      "Total patients: 364\n",
      "Total failures: 97\n",
      "Total IMV failures: 79\n",
      "Total Death failures: 14\n",
      "Both failures: 4\n"
     ]
    }
   ],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create a new dataframe of IMV events (within 48h — already filtered by cell 4)\n",
    "imv_df = df[df['device_category'] == 'IMV'].copy()\n",
    "# Identify IMV hospitalizations\n",
    "imv_ids = imv_df['hospitalization_id'].unique()\n",
    "\n",
    "# Death within 48h of NIPPV initiation\n",
    "# discharge_category is hospitalization-level; use discharge_dttm to time-bound\n",
    "if 'discharge_dttm' in df.columns:\n",
    "    df['discharge_dttm'] = pd.to_datetime(df['discharge_dttm'], utc=True)\n",
    "    # Get per-patient discharge info\n",
    "    discharge_info = df.groupby('hospitalization_id').agg({\n",
    "        'discharge_category': 'first',\n",
    "        'discharge_dttm': 'first',\n",
    "        'nippv_start_time': 'first'\n",
    "    }).reset_index()\n",
    "    discharge_info['hours_to_discharge'] = (\n",
    "        discharge_info['discharge_dttm'] - discharge_info['nippv_start_time']\n",
    "    ).dt.total_seconds() / 3600\n",
    "    # Only count deaths within 48h of NIPPV start\n",
    "    expired_ids = discharge_info[\n",
    "        (discharge_info['discharge_category'] == 'Expired') &\n",
    "        (discharge_info['hours_to_discharge'] <= 48)\n",
    "    ]['hospitalization_id'].unique()\n",
    "    n_late_deaths = len(discharge_info[\n",
    "        (discharge_info['discharge_category'] == 'Expired') &\n",
    "        (discharge_info['hours_to_discharge'] > 48)\n",
    "    ])\n",
    "    print(f\"Deaths time-bounded to 48h using discharge_dttm\")\n",
    "    print(f\"  Late deaths excluded (>48h): {n_late_deaths}\")\n",
    "else:\n",
    "    # Fallback: use discharge_category without time-bounding\n",
    "    expired_df = df[df['discharge_category'] == 'Expired'].copy()\n",
    "    expired_ids = expired_df['hospitalization_id'].unique()\n",
    "    print(\"WARNING: discharge_dttm not available in wide dataset\")\n",
    "    print(\"  Death outcome includes ALL in-hospital deaths, not only within 48h\")\n",
    "    print(\"  To fix: ensure 01_wide_generator.py exports discharge_dttm from hospitalization table\")\n",
    "\n",
    "# Create separate failure flags\n",
    "df['failure_imv'] = df['hospitalization_id'].isin(imv_ids).astype(int)\n",
    "df['failure_death'] = df['hospitalization_id'].isin(expired_ids).astype(int)\n",
    "\n",
    "# Overall failure: either IMV or death (within 48h)\n",
    "df['failure'] = ((df['failure_imv'] == 1) | (df['failure_death'] == 1)).astype(int)\n",
    "\n",
    "# Count totals (unique hospitalizations)\n",
    "total_patients = df['hospitalization_id'].nunique()\n",
    "total_failures = df[df['failure'] == 1]['hospitalization_id'].nunique()\n",
    "imv_failures = df[df['failure_imv'] == 1]['hospitalization_id'].nunique()\n",
    "death_failures = df[df['failure_death'] == 1]['hospitalization_id'].nunique()\n",
    "both_failures = df[(df['failure_imv'] == 1) & (df['failure_death'] == 1)]['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total patients and failures\n",
    "print(f'Total patients: {total_patients}')\n",
    "consort[\"patients_pre_missing\"] = total_patients\n",
    "print(f'Total failures: {total_failures}')\n",
    "consort[\"failures_pre_missing\"] = total_failures\n",
    "print(f'Total IMV failures: {imv_failures - both_failures}')\n",
    "consort[\"imv_fail_pre_missing\"] = imv_failures - both_failures\n",
    "print(f'Total Death failures: {death_failures - both_failures}')\n",
    "consort[\"death_fail_pre_missing\"] = death_failures - both_failures\n",
    "print(f'Both failures: {both_failures}')\n",
    "consort[\"both_fail_pre_missing\"] = both_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.444002Z",
     "iopub.status.busy": "2026-02-19T15:42:32.443942Z",
     "iopub.status.idle": "2026-02-19T15:42:32.452622Z",
     "shell.execute_reply": "2026-02-19T15:42:32.452276Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# PREDICTOR EXTRACTION: Median values 1–12 hours post-NIPPV\n",
    "# NOTE: This window overlaps with the outcome window (0–48h).\n",
    "# Predictors reflect early treatment response; this overlap is\n",
    "# acceptable per protocol but should be acknowledged in the manuscript.\n",
    "# =====================================================\n",
    "\n",
    "# Filter events 1–12 hours after NIPPV (.copy() prevents SettingWithCopyWarning in cells 11-12)\n",
    "df_PostNIPPV_window = df[(df['time_since_nippv'] >= 1) & (df['time_since_nippv'] <= 12)].copy()\n",
    "\n",
    "# Sort to ensure earliest events first\n",
    "df_PostNIPPV_window = df_PostNIPPV_window.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "# Get the median heart rate within the 1–12 hour window\n",
    "heart_rate_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['heart_rate']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'heart_rate': 'heart_rate_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(heart_rate_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.453722Z",
     "iopub.status.busy": "2026-02-19T15:42:32.453665Z",
     "iopub.status.idle": "2026-02-19T15:42:32.459824Z",
     "shell.execute_reply": "2026-02-19T15:42:32.459486Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the median respiratory rate within the 1-12 hour window\n",
    "resp_rate_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['respiratory_rate']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'respiratory_rate': 'respiratory_rate_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(resp_rate_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.460770Z",
     "iopub.status.busy": "2026-02-19T15:42:32.460719Z",
     "iopub.status.idle": "2026-02-19T15:42:32.466978Z",
     "shell.execute_reply": "2026-02-19T15:42:32.466589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine arterial and venous PCO2 (prioritize arterial when both available)\n",
    "# NOTE: pCO2 values are clinically similar between arterial and venous blood;\n",
    "# the key difference between ABG/VBG is PaO2, which is not used in this study.\n",
    "df_PostNIPPV_window['PostNIPPV_pco2_combined'] = df_PostNIPPV_window['pco2_arterial'].combine_first(df_PostNIPPV_window['pco2_venous'])\n",
    "\n",
    "# Get median combined PCO2 in window\n",
    "pco2_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['PostNIPPV_pco2_combined']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'PostNIPPV_pco2_combined': 'pco2_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back\n",
    "df = df.merge(pco2_PostNIPPV_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.467935Z",
     "iopub.status.busy": "2026-02-19T15:42:32.467873Z",
     "iopub.status.idle": "2026-02-19T15:42:32.473953Z",
     "shell.execute_reply": "2026-02-19T15:42:32.473667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine arterial and venous pH (prioritize arterial when both available)\n",
    "# NOTE: pH is clinically similar between arterial and venous blood.\n",
    "df_PostNIPPV_window['PostNIPPV_ph_combined'] = df_PostNIPPV_window['ph_arterial'].combine_first(df_PostNIPPV_window['ph_venous'])\n",
    "\n",
    "# Get median combined pH in window\n",
    "ph_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['PostNIPPV_ph_combined']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'PostNIPPV_ph_combined': 'ph_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back into main df\n",
    "df = df.merge(ph_PostNIPPV_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.474917Z",
     "iopub.status.busy": "2026-02-19T15:42:32.474851Z",
     "iopub.status.idle": "2026-02-19T15:42:32.480400Z",
     "shell.execute_reply": "2026-02-19T15:42:32.480137Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the median peep_set within the 1-12 hour window\n",
    "peep_set_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['peep_set']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'peep_set': 'peep_set_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(peep_set_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.481414Z",
     "iopub.status.busy": "2026-02-19T15:42:32.481362Z",
     "iopub.status.idle": "2026-02-19T15:42:32.486954Z",
     "shell.execute_reply": "2026-02-19T15:42:32.486691Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the median tidal_volume_obs within the 1-12 hour window\n",
    "tidal_volume_obs_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['tidal_volume_obs']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tidal_volume_obs': 'tidal_volume_obs_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(tidal_volume_obs_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.487942Z",
     "iopub.status.busy": "2026-02-19T15:42:32.487888Z",
     "iopub.status.idle": "2026-02-19T15:42:32.493678Z",
     "shell.execute_reply": "2026-02-19T15:42:32.493261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the median fio2_set within the 1–12 hour window\n",
    "fio2_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['fio2_set']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'fio2_set': 'fio2_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(fio2_PostNIPPV_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.494533Z",
     "iopub.status.busy": "2026-02-19T15:42:32.494478Z",
     "iopub.status.idle": "2026-02-19T15:42:32.500034Z",
     "shell.execute_reply": "2026-02-19T15:42:32.499751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the median fio2_set within the 1–12 hour window\n",
    "map_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['map']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'map': 'map_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(map_PostNIPPV_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.500887Z",
     "iopub.status.busy": "2026-02-19T15:42:32.500834Z",
     "iopub.status.idle": "2026-02-19T15:42:32.505279Z",
     "shell.execute_reply": "2026-02-19T15:42:32.505051Z"
    }
   },
   "outputs": [],
   "source": [
    "df_analytic = df.groupby('hospitalization_id').agg({\n",
    "    'age_at_admission': 'first',\n",
    "    'sex_category': 'first',\n",
    "    'map_after_NIPPV': 'first',\n",
    "    'peep_set_after_NIPPV': 'first',\n",
    "    'tidal_volume_obs_after_NIPPV': 'first',\n",
    "    'heart_rate_after_NIPPV': 'first',\n",
    "    'respiratory_rate_after_NIPPV': 'first',\n",
    "    'ph_after_NIPPV': 'first',\n",
    "    'pco2_after_NIPPV': 'first',\n",
    "    'fio2_after_NIPPV': 'first',\n",
    "    'failure_imv':'first',\n",
    "    'failure_death':'first',\n",
    "    'failure': 'first'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.506212Z",
     "iopub.status.busy": "2026-02-19T15:42:32.506161Z",
     "iopub.status.idle": "2026-02-19T15:42:32.512227Z",
     "shell.execute_reply": "2026-02-19T15:42:32.511913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness table exported for site: mimic\n",
      "                    variable  N_total  N_missing  N_observed  Pct_missing  site\n",
      "            age_at_admission      364          0         364          0.0 mimic\n",
      "                sex_category      364          0         364          0.0 mimic\n",
      "             map_after_NIPPV      364          0         364          0.0 mimic\n",
      "        peep_set_after_NIPPV      364        109         255         29.9 mimic\n",
      "tidal_volume_obs_after_NIPPV      364        169         195         46.4 mimic\n",
      "      heart_rate_after_NIPPV      364          0         364          0.0 mimic\n",
      "respiratory_rate_after_NIPPV      364          0         364          0.0 mimic\n",
      "              ph_after_NIPPV      364         48         316         13.2 mimic\n",
      "            pco2_after_NIPPV      364         49         315         13.5 mimic\n",
      "            fio2_after_NIPPV      364         91         273         25.0 mimic\n",
      "                     failure      364          0         364          0.0 mimic\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# MISSINGNESS TABLE (TRIPOD+AI + STROBE required)\n",
    "# Generated BEFORE complete case deletion\n",
    "# =====================================================\n",
    "\n",
    "predictor_cols = [\n",
    "    'age_at_admission', 'sex_category', 'map_after_NIPPV',\n",
    "    'peep_set_after_NIPPV', 'tidal_volume_obs_after_NIPPV',\n",
    "    'heart_rate_after_NIPPV', 'respiratory_rate_after_NIPPV',\n",
    "    'ph_after_NIPPV', 'pco2_after_NIPPV', 'fio2_after_NIPPV'\n",
    "]\n",
    "\n",
    "missingness_rows = []\n",
    "n_total = len(df_analytic)\n",
    "for col in predictor_cols:\n",
    "    n_missing = int(df_analytic[col].isna().sum())\n",
    "    missingness_rows.append({\n",
    "        'variable': col,\n",
    "        'N_total': n_total,\n",
    "        'N_missing': n_missing,\n",
    "        'N_observed': n_total - n_missing,\n",
    "        'Pct_missing': round(100 * n_missing / n_total, 1) if n_total > 0 else 0\n",
    "    })\n",
    "\n",
    "# Also add the outcome variable\n",
    "n_fail_missing = int(df_analytic['failure'].isna().sum())\n",
    "missingness_rows.append({\n",
    "    'variable': 'failure',\n",
    "    'N_total': n_total,\n",
    "    'N_missing': n_fail_missing,\n",
    "    'N_observed': n_total - n_fail_missing,\n",
    "    'Pct_missing': round(100 * n_fail_missing / n_total, 1) if n_total > 0 else 0\n",
    "})\n",
    "\n",
    "missingness_df = pd.DataFrame(missingness_rows)\n",
    "missingness_df['site'] = SITE\n",
    "\n",
    "os.makedirs('../output_to_share/no_bmi', exist_ok=True)\n",
    "missingness_df.to_csv('../output_to_share/no_bmi/missingness_table.csv', index=False)\n",
    "\n",
    "print(f\"Missingness table exported for site: {SITE}\")\n",
    "print(missingness_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.512991Z",
     "iopub.status.busy": "2026-02-19T15:42:32.512931Z",
     "iopub.status.idle": "2026-02-19T15:42:32.514751Z",
     "shell.execute_reply": "2026-02-19T15:42:32.514508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Complete case analysis: drop rows with missing values in predictor or outcome columns only\n",
    "# (not all columns — hospitalization_id, failure_imv, failure_death are never missing)\n",
    "required_cols = [\n",
    "    'age_at_admission', 'sex_category', 'map_after_NIPPV',\n",
    "    'pco2_after_NIPPV', 'ph_after_NIPPV', 'peep_set_after_NIPPV',\n",
    "    'tidal_volume_obs_after_NIPPV', 'heart_rate_after_NIPPV',\n",
    "    'respiratory_rate_after_NIPPV', 'fio2_after_NIPPV', 'failure'\n",
    "]\n",
    "df_analytic_clean = df_analytic.dropna(subset=required_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.515405Z",
     "iopub.status.busy": "2026-02-19T15:42:32.515360Z",
     "iopub.status.idle": "2026-02-19T15:42:32.517107Z",
     "shell.execute_reply": "2026-02-19T15:42:32.516793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients before dropping missing data: 364\n",
      "Total patients after dropping missing data: 177\n"
     ]
    }
   ],
   "source": [
    "#Print total number of patients before dropping missing data\n",
    "admissions = df_analytic['hospitalization_id'].nunique()\n",
    "print(f'Total patients before dropping missing data: {admissions}')\n",
    "\n",
    "#Print total number of patients after dropping missing data\n",
    "admissions = df_analytic_clean['hospitalization_id'].nunique()\n",
    "print(f'Total patients after dropping missing data: {admissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.517960Z",
     "iopub.status.busy": "2026-02-19T15:42:32.517907Z",
     "iopub.status.idle": "2026-02-19T15:42:32.521664Z",
     "shell.execute_reply": "2026-02-19T15:42:32.521336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure we have a copy to avoid warnings\n",
    "df_analytic_clean = df_analytic_clean.copy()\n",
    "\n",
    "# Scale continuous variables\n",
    "df_analytic_clean.loc[:, 'age_scale'] = (df_analytic_clean['age_at_admission'] - df_analytic_clean['age_at_admission'].mean()) / 10\n",
    "df_analytic_clean.loc[:, 'pco2_scale'] = (df_analytic_clean['pco2_after_NIPPV'] - df_analytic_clean['pco2_after_NIPPV'].mean()) / 10\n",
    "df_analytic_clean.loc[:, 'ph_scale'] = (df_analytic_clean['ph_after_NIPPV'] - df_analytic_clean['ph_after_NIPPV'].mean()) / 0.1\n",
    "df_analytic_clean.loc[:, 'rr_scale'] = (df_analytic_clean['respiratory_rate_after_NIPPV'] - df_analytic_clean['respiratory_rate_after_NIPPV'].mean()) / 5\n",
    "df_analytic_clean.loc[:, 'hr_scale'] = (df_analytic_clean['heart_rate_after_NIPPV'] - df_analytic_clean['heart_rate_after_NIPPV'].mean()) / 10\n",
    "df_analytic_clean.loc[:, 'tidal_volume_scale'] = (df_analytic_clean['tidal_volume_obs_after_NIPPV'] - df_analytic_clean['tidal_volume_obs_after_NIPPV'].mean()) / 100\n",
    "df_analytic_clean['peep_scale'] = (df_analytic_clean['peep_set_after_NIPPV'] - df_analytic_clean['peep_set_after_NIPPV'].mean()) / 2\n",
    "df_analytic_clean.loc[:, 'map_scale'] = (df_analytic_clean['map_after_NIPPV'] - df_analytic_clean['map_after_NIPPV'].mean()) / 10\n",
    "\n",
    "\n",
    "# Binary variables\n",
    "df_analytic_clean.loc[:, 'female'] = (df_analytic_clean['sex_category'] == 'Female').astype(int)\n",
    "df_analytic_clean.loc[:, 'fio2_high'] = (df_analytic_clean['fio2_after_NIPPV'] > 0.40).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.522465Z",
     "iopub.status.busy": "2026-02-19T15:42:32.522409Z",
     "iopub.status.idle": "2026-02-19T15:42:32.525642Z",
     "shell.execute_reply": "2026-02-19T15:42:32.525270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export final df to CSV\n",
    "os.makedirs('../output/no_bmi', exist_ok=True)\n",
    "df_analytic_clean.to_csv('../output/no_bmi/NIPPV_analytic_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.526416Z",
     "iopub.status.busy": "2026-02-19T15:42:32.526366Z",
     "iopub.status.idle": "2026-02-19T15:42:32.528881Z",
     "shell.execute_reply": "2026-02-19T15:42:32.528565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patients: 177\n",
      "Total failures: 72\n",
      "Total IMV failures: 64\n",
      "Total death failures: 5\n",
      "Both failures: 3\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows\n",
    "total_rows = len(df_analytic_clean)\n",
    "\n",
    "# Total number of failures (failure == 1)\n",
    "total_failures = df_analytic_clean['failure'].sum()\n",
    "imv_failures = df_analytic_clean['failure_imv'].sum()\n",
    "death_failures = df_analytic_clean['failure_death'].sum()\n",
    "both_failures = df_analytic_clean[(df_analytic_clean['failure_imv'] == 1) & (df_analytic_clean['failure_death'] == 1)]['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total patients and failures\n",
    "print(f'Total Patients: {total_rows}')\n",
    "consort[\"patients_post_missing\"] = total_rows\n",
    "print(f'Total failures: {total_failures}')\n",
    "consort[\"failures_post_missing\"] = total_failures\n",
    "print(f'Total IMV failures: {imv_failures - both_failures}')\n",
    "consort[\"imv_fail_post_missing\"] = imv_failures - both_failures\n",
    "print(f'Total death failures: {death_failures - both_failures}')\n",
    "consort[\"death_fail_post_missing\"] = death_failures - both_failures\n",
    "print(f'Both failures: {both_failures}')\n",
    "consort[\"both_fail_post_missing\"] = both_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T15:42:32.529714Z",
     "iopub.status.busy": "2026-02-19T15:42:32.529656Z",
     "iopub.status.idle": "2026-02-19T15:42:32.534417Z",
     "shell.execute_reply": "2026-02-19T15:42:32.534171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSORT data exported for site: mimic\n",
      " step                                    description  n_remaining  n_excluded                                             exclusion_reason  site n_failure_yes n_failure_no\n",
      "    1                    Total ICU admissions loaded         5468         NaN                                                         None mimic          None         None\n",
      "    2  NIPPV initiated within 6h of first vital sign         2553      2915.0                  No NIPPV within 6 hours of first vital sign mimic          None         None\n",
      "    3                           Baseline FiO2 <= 60%         1056      1497.0 Baseline FiO2 > 60% (possible hypoxemic respiratory failure) mimic          None         None\n",
      "    4                       Baseline pCO2 >= 45 mmHg          458       598.0                              pCO2 < 45 mmHg (no hypercapnia) mimic          None         None\n",
      "    5                            Baseline pH <= 7.35          364        94.0                          pH > 7.35 (no respiratory acidosis) mimic          None         None\n",
      "    6 Complete case analysis (no missing predictors)          177       187.0                                       Missing predictor data mimic            72          105\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =====================================================\n",
    "# EXPORT CONSORT DATA — Structured for Flow Diagram\n",
    "# =====================================================\n",
    "os.makedirs('../output_to_share/no_bmi', exist_ok=True)\n",
    "\n",
    "# Original flat format (backward compatible)\n",
    "consort_flat = pd.DataFrame([consort])\n",
    "consort_flat['site'] = SITE\n",
    "consort_flat.to_csv('../output_to_share/no_bmi/consort.csv', index=False)\n",
    "\n",
    "# Structured flow diagram format (for manuscript Figure 1)\n",
    "flow_steps = [\n",
    "    {\n",
    "        'step': 1,\n",
    "        'description': 'Total ICU admissions loaded',\n",
    "        'n_remaining': consort['total_admissions'],\n",
    "        'n_excluded': None,\n",
    "        'exclusion_reason': None\n",
    "    },\n",
    "    {\n",
    "        'step': 2,\n",
    "        'description': 'NIPPV initiated within 6h of first vital sign',\n",
    "        'n_remaining': consort['total_nippv_6h'],\n",
    "        'n_excluded': consort['total_admissions'] - consort['total_nippv_6h'],\n",
    "        'exclusion_reason': 'No NIPPV within 6 hours of first vital sign'\n",
    "    },\n",
    "    {\n",
    "        'step': 3,\n",
    "        'description': 'Baseline FiO2 <= 60%',\n",
    "        'n_remaining': consort['total_fio2_60'],\n",
    "        'n_excluded': consort['total_nippv_6h'] - consort['total_fio2_60'],\n",
    "        'exclusion_reason': 'Baseline FiO2 > 60% (possible hypoxemic respiratory failure)'\n",
    "    },\n",
    "    {\n",
    "        'step': 4,\n",
    "        'description': 'Baseline pCO2 >= 45 mmHg',\n",
    "        'n_remaining': consort['total_pco2_45'],\n",
    "        'n_excluded': consort['total_fio2_60'] - consort['total_pco2_45'],\n",
    "        'exclusion_reason': 'pCO2 < 45 mmHg (no hypercapnia)'\n",
    "    },\n",
    "    {\n",
    "        'step': 5,\n",
    "        'description': 'Baseline pH <= 7.35',\n",
    "        'n_remaining': consort['total_ph_7.35'],\n",
    "        'n_excluded': consort['total_pco2_45'] - consort['total_ph_7.35'],\n",
    "        'exclusion_reason': 'pH > 7.35 (no respiratory acidosis)'\n",
    "    },\n",
    "    {\n",
    "        'step': 6,\n",
    "        'description': 'Complete case analysis (no missing predictors)',\n",
    "        'n_remaining': consort['patients_post_missing'],\n",
    "        'n_excluded': consort['patients_pre_missing'] - consort['patients_post_missing'],\n",
    "        'exclusion_reason': 'Missing predictor data'\n",
    "    }\n",
    "]\n",
    "\n",
    "consort_flow = pd.DataFrame(flow_steps)\n",
    "consort_flow['site'] = SITE\n",
    "consort_flow['n_failure_yes'] = None\n",
    "consort_flow['n_failure_no'] = None\n",
    "\n",
    "# Fill in failure breakdown for final step\n",
    "consort_flow.loc[consort_flow['step'] == 6, 'n_failure_yes'] = consort['failures_post_missing']\n",
    "consort_flow.loc[consort_flow['step'] == 6, 'n_failure_no'] = (\n",
    "    consort['patients_post_missing'] - consort['failures_post_missing']\n",
    ")\n",
    "\n",
    "consort_flow.to_csv('../output_to_share/no_bmi/consort_flow.csv', index=False)\n",
    "\n",
    "print(f\"CONSORT data exported for site: {SITE}\")\n",
    "print(consort_flow.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
