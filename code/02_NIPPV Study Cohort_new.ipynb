{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create structure for consort data information\n",
    "consort = { \n",
    "    #initial data information\n",
    "    \"total_rows_loaded\": None,\n",
    "    \"total_admissions\": None,\n",
    "\n",
    "    #inclusion/exclusion criteria\n",
    "    \"total_nippv_6h\": None,\n",
    "    \"total_fio2_60\": None,\n",
    "    \"total_pco2_45\": None,\n",
    "    \"total_ph_7.35\": None,\n",
    "\n",
    "    #cohort size and failures BEFORE dropping missing data\n",
    "    \"patients_pre_missing\": None,\n",
    "    \"failures_pre_missing\": None,\n",
    "    \"imv_fail_pre_missing\": None,\n",
    "    \"death_fail_pre_missing\": None,\n",
    "    \"both_fail_pre_missing\": None,\n",
    "\n",
    "    #cohort size and failures AFTER dropping missing data\n",
    "    \"patients_post_missing\": None,\n",
    "    \"failures_post_missing\": None,\n",
    "    \"imv_fail_post_missing\": None,\n",
    "    \"death_fail_post_missing\": None,\n",
    "    \"both_fail_post_missing\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import dataset\n",
    "df = pd.read_parquet('../output/study_cohort_NIPPV_&_ICU.parquet')\n",
    "\n",
    "print(f'Total rows loaded: {len(df)}')\n",
    "consort[\"total_rows_loaded\"] = len(df)\n",
    "\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total ICU NIPPV Admissions: {admissions}')\n",
    "consort[\"total_admissions\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to standard pandas datetime\n",
    "df['event_time'] = pd.to_datetime(df['event_time'], utc = True)\n",
    "df['admission_dttm'] = pd.to_datetime(df['admission_dttm'], utc = True)\n",
    "\n",
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "vital_sign_cols = ['heart_rate', 'respiratory_rate', 'spo2', 'sbp', 'temp_c']\n",
    "\n",
    "# Identify First Vital Sign\n",
    "vitals = df[df[vital_sign_cols].notna().any(axis=1)]\n",
    "vitals = vitals.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "first_vital = (\n",
    "    vitals.groupby('hospitalization_id')\n",
    "          .first()\n",
    "          .reset_index()[['hospitalization_id', 'event_time']]\n",
    "          .rename(columns={'event_time': 'first_vital_time'})\n",
    ")\n",
    "\n",
    "# Identify First NIPPV\n",
    "nippv = df[df['device_category'] == 'NIPPV']\n",
    "nippv = nippv.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "first_nippv = (\n",
    "    nippv.groupby('hospitalization_id')\n",
    "         .first()\n",
    "         .reset_index()[['hospitalization_id', 'event_time']]\n",
    "         .rename(columns={'event_time': 'first_nippv_time'})\n",
    ")\n",
    "\n",
    "# Merge First NIPPV with First Vital and Calculate Time differene\n",
    "merged = first_vital.merge(first_nippv, on='hospitalization_id')\n",
    "merged['time_to_NIPPV'] = (\n",
    "    merged['first_nippv_time'] - merged['first_vital_time']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Filter dataframe to contain only hospitalizations where NIPPV occured within 6 hours of first vital sign\n",
    "eligible_ids = merged[merged['time_to_NIPPV'] <= 6]['hospitalization_id']\n",
    "df = df[df['hospitalization_id'].isin(eligible_ids)]\n",
    "\n",
    "# Merge time_to_NIPPV and first_vital_time back into main dataframe\n",
    "df = df.merge(\n",
    "    merged[['hospitalization_id', 'time_to_NIPPV']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "df = df.merge(\n",
    "    first_vital[['hospitalization_id', 'first_vital_time']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Print total rows and admissions\n",
    "print(f'Total rows loaded: {len(df)}')\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total NIPPV < 6 hrs: {admissions}')\n",
    "consort[\"total_nippv_6h\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Calculate nippv_start_time\n",
    "df['nippv_start_time'] = (\n",
    "    df['first_vital_time'] + pd.to_timedelta(df['time_to_NIPPV'], unit='h')\n",
    ")\n",
    "\n",
    "#Calculate time_since_nippv\n",
    "df['time_since_nippv'] = (\n",
    "    df['event_time'] - df['nippv_start_time']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "#Filter to rows w/in 48 hours of NIPPV start\n",
    "df = df[df['time_since_nippv'] <= 48]\n",
    "\n",
    "# Print total rows and admissions\n",
    "print(f'Total rows loaded: {len(df)}')\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total NIPPV < 6 hrs: {admissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Filter to 1 hour after NIPPV initiation\n",
    "df_PreNIPPV = df[df['event_time'] < df['nippv_start_time'] + pd.Timedelta(hours=1)]\n",
    "\n",
    "# Get the maximum fio2_set for each hospitalization_id prior to NIPPV initiation\n",
    "max_fio2_PreNIPPV = df_PreNIPPV.groupby('hospitalization_id')['fio2_set'].max().reset_index()\n",
    "\n",
    "# Identify eligible hospitalizations where max fio2_set <= .6 prior to NIPPV initiation\n",
    "eligible_fio2 = max_fio2_PreNIPPV[max_fio2_PreNIPPV['fio2_set'] <= .6]['hospitalization_id']\n",
    "\n",
    "# Filter the df to keep only eligible fio2 hospitalizations\n",
    "df = df[df['hospitalization_id'].isin(eligible_fio2)].reset_index(drop=True)\n",
    "\n",
    "#Print total admissions\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "print(f'Total NIPPV < 6 hrs & fio2_set <= 60: {admissions}')\n",
    "consort[\"total_fio2_60\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Update df_PreNIPPV with only filtered admissions\n",
    "df_PreNIPPV = df[df['event_time'] < df['nippv_start_time'] + pd.Timedelta(hours=1)]\n",
    "\n",
    "# Get minimum pco2_arterial and pco2_venous prior to NIPPV initiation for each hospitalization_id\n",
    "min_pco2_arterial = df_PreNIPPV.groupby('hospitalization_id')['pco2_arterial'].min()\n",
    "min_pco2_venous = df_PreNIPPV.groupby('hospitalization_id')['pco2_venous'].min()\n",
    "\n",
    "# Combine min_pco2_arterial and min_pco2_venous into one dataframe\n",
    "min_pco2 = pd.DataFrame({\n",
    "    'pco2_arterial': min_pco2_arterial,\n",
    "    'pco2_venous': min_pco2_venous\n",
    "}).reset_index()\n",
    "\n",
    "# Filter rows where min_pco2_arterial or min_pco2_venous >= 45\n",
    "eligible_pco2 = min_pco2[\n",
    "    (min_pco2['pco2_arterial'] >= 45) | (min_pco2['pco2_venous'] >= 45)\n",
    "]['hospitalization_id']\n",
    "\n",
    "# Filter the df to keep only eligible pco2 hospitalizations\n",
    "df = df[df['hospitalization_id'].isin(eligible_pco2)].reset_index(drop=True)\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total admissions\n",
    "print(f'Total NIPPV < 6 hrs & fio2_set <= 60 & pco2 >= 45: {len(eligible_pco2)}')\n",
    "consort[\"total_pco2_45\"] = len(eligible_pco2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Update df_PreNIPPV with only filtered admissions\n",
    "df_PreNIPPV = df[df['event_time'] < df['nippv_start_time'] + pd.Timedelta(hours=1)]\n",
    "\n",
    "# Get maximum ph_arterial and ph_venous prior to NIPPV initiation for each hospitalization_id\n",
    "max_ph_arterial = df_PreNIPPV.groupby('hospitalization_id')['ph_arterial'].max()\n",
    "max_ph_venous = df_PreNIPPV.groupby('hospitalization_id')['ph_venous'].max()\n",
    "\n",
    "# Combine max_ph_arterial and max_ph_venous into one dataframe\n",
    "max_ph = pd.DataFrame({\n",
    "    'ph_arterial': max_ph_arterial,\n",
    "    'ph_venous': max_ph_venous\n",
    "}).reset_index()\n",
    "\n",
    "# Filter to rows where max_ph_arterial or max_ph_venous <= 7.35\n",
    "eligible_ph = max_ph[\n",
    "    (max_ph['ph_arterial'] <= 7.35) | (max_ph['ph_venous'] <= 7.35)\n",
    "]['hospitalization_id']\n",
    "\n",
    "# Filter the df to keep only eligible ph hospitalizations\n",
    "df = df[df['hospitalization_id'].isin(eligible_ph)].reset_index(drop=True)\n",
    "admissions = df['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total admissions\n",
    "print(f'Total NIPPV < 6 hrs & fio2_set <= 60 & pco2 >= 45 & ph <= 7.35: {len(eligible_ph)}')\n",
    "consort[\"total_ph_7.35\"] = admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create a new dataframe of IMV events\n",
    "imv_df = df[df['device_category'] == 'IMV'].copy()\n",
    "# Identify IMV hospitalizations\n",
    "imv_ids = imv_df['hospitalization_id'].unique()\n",
    "\n",
    "# Create a new dataframe of patients who died\n",
    "expired_df = df[df['discharge_category'] == 'Expired'].copy()\n",
    "# Identify who died\n",
    "expired_ids = expired_df['hospitalization_id'].unique()\n",
    "\n",
    "# Create separate failure flags\n",
    "df['failure_imv'] = df['hospitalization_id'].isin(imv_ids).astype(int)\n",
    "df['failure_death'] = df['hospitalization_id'].isin(expired_ids).astype(int)\n",
    "\n",
    "# Overall failure: either IMV or death\n",
    "df['failure'] = ((df['failure_imv'] == 1) | (df['failure_death'] == 1)).astype(int)\n",
    "\n",
    "# Count totals (unique hospitalizations)\n",
    "total_patients = df['hospitalization_id'].nunique()\n",
    "total_failures = df[df['failure'] == 1]['hospitalization_id'].nunique()\n",
    "imv_failures = df[df['failure_imv'] == 1]['hospitalization_id'].nunique()\n",
    "death_failures = df[df['failure_death'] == 1]['hospitalization_id'].nunique()\n",
    "both_failures = df[(df['failure_imv'] == 1) & (df['failure_death'] == 1)]['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total patients and failures\n",
    "print(f'Total patients: {total_patients}')\n",
    "consort[\"patients_pre_missing\"] = total_patients\n",
    "print(f'Total failures: {total_failures}')\n",
    "consort[\"failures_pre_missing\"] = total_failures\n",
    "print(f'Total IMV failures: {imv_failures - both_failures}')\n",
    "consort[\"imv_fail_pre_missing\"] = imv_failures - both_failures\n",
    "print(f'Total Death failures: {death_failures - both_failures}')\n",
    "consort[\"death_fail_pre_missing\"] = death_failures - both_failures\n",
    "print(f'Both failures: {both_failures}')\n",
    "consort[\"both_fail_pre_missing\"] = both_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter events 1–12 hours after NIPPV\n",
    "df_PostNIPPV_window = df[(df['time_since_nippv'] >= 1) & (df['time_since_nippv'] <= 12)]\n",
    "\n",
    "# Sort to ensure earliest events first\n",
    "df_PostNIPPV_window = df_PostNIPPV_window.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "# Get the first heart rate within the 1–12 hour window\n",
    "heart_rate_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['heart_rate']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'heart_rate': 'heart_rate_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(heart_rate_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the first respiratory rate within the 1-12 hour window\n",
    "resp_rate_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['respiratory_rate']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'respiratory_rate': 'respiratory_rate_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(resp_rate_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine arterial and venous PCO2\n",
    "df_PostNIPPV_window['PostNIPPV_pco2_combined'] = df_PostNIPPV_window['pco2_arterial'].combine_first(df_PostNIPPV_window['pco2_venous'])\n",
    "\n",
    "# Get first combined PCO2 in window\n",
    "pco2_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['PostNIPPV_pco2_combined']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'PostNIPPV_pco2_combined': 'pco2_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back\n",
    "df = df.merge(pco2_PostNIPPV_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine arterial and venous pH\n",
    "df_PostNIPPV_window['PostNIPPV_ph_combined'] = df_PostNIPPV_window['ph_arterial'].combine_first(df_PostNIPPV_window['ph_venous'])\n",
    "\n",
    "# Get first combined pH in window\n",
    "ph_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['PostNIPPV_ph_combined']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'PostNIPPV_ph_combined': 'ph_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back into main df\n",
    "df = df.merge(ph_PostNIPPV_window, on='hospitalization_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the first peep_set within the 1-12 hour window\n",
    "peep_set_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['peep_set']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'peep_set': 'peep_set_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(peep_set_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the first tidal_volume_obs within the 1-12 hour window\n",
    "tidal_volume_obs_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['tidal_volume_obs']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tidal_volume_obs': 'tidal_volume_obs_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(tidal_volume_obs_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first fio2_set within the 1–12 hour window\n",
    "fio2_PostNIPPV_window = (\n",
    "    df_PostNIPPV_window.groupby('hospitalization_id')['fio2_set']\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'fio2_set': 'fio2_after_NIPPV'})\n",
    ")\n",
    "\n",
    "# Merge back to main df\n",
    "df = df.merge(fio2_PostNIPPV_window, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create combined pco2 column\n",
    "df['pco2_combined'] = df['pco2_arterial'].combine_first(df['pco2_venous'])\n",
    "\n",
    "# Sort by hospitalization and event time\n",
    "df = df.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "# Get initial pco2_combined for each hospitalization\n",
    "initial_pco2 = df.groupby('hospitalization_id')['pco2_combined'].first().reset_index()\n",
    "initial_pco2 = initial_pco2.rename(columns={'pco2_combined': 'first_pco2'})\n",
    "\n",
    "# Merge back into main df\n",
    "df = df.merge(initial_pco2, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by hospitalization_id and reset index after sorting\n",
    "df = df.sort_values(by = ['hospitalization_id', 'event_time'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Create combined ph column\n",
    "df['ph_combined'] = df['ph_arterial'].combine_first(df['ph_venous'])\n",
    "\n",
    "# Sort by hospitalization and event time\n",
    "df = df.sort_values(['hospitalization_id', 'event_time'])\n",
    "\n",
    "# Get initial ph_combined for each hospitalization\n",
    "initial_ph = df.groupby('hospitalization_id')['ph_combined'].first().reset_index()\n",
    "initial_ph = initial_ph.rename(columns={'ph_combined': 'first_ph'})\n",
    "\n",
    "# Merge back into main df\n",
    "df = df.merge(initial_ph, on='hospitalization_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytic = df.groupby('hospitalization_id').agg({\n",
    "    'age_at_admission': 'first',\n",
    "    'sex_category': 'first',\n",
    "    'map': 'median',\n",
    "    'peep_set_after_NIPPV': 'first',\n",
    "    'tidal_volume_obs_after_NIPPV': 'first',\n",
    "    'heart_rate_after_NIPPV': 'first',\n",
    "    'respiratory_rate_after_NIPPV': 'first',\n",
    "    'ph_after_NIPPV': 'first',\n",
    "    'pco2_after_NIPPV': 'first',\n",
    "    'fio2_after_NIPPV': 'first',\n",
    "    'failure_imv':'first',\n",
    "    'failure_death':'first',\n",
    "    'failure': 'first'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values\n",
    "df_analytic_clean = df_analytic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print total number of patients before dropping missing data\n",
    "admissions = df_analytic['hospitalization_id'].nunique()\n",
    "print(f'Total patients before dropping missing data: {admissions}')\n",
    "\n",
    "#Print total number of patients after dropping missing data\n",
    "admissions = df_analytic_clean['hospitalization_id'].nunique()\n",
    "print(f'Total patients after dropping missing data: {admissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have a copy to avoid warnings\n",
    "df_analytic_clean = df_analytic_clean.copy()\n",
    "\n",
    "# Scale continuous variables\n",
    "df_analytic_clean.loc[:, 'age_scale'] = (df_analytic_clean['age_at_admission'] - df_analytic_clean['age_at_admission'].mean()) / 10\n",
    "df_analytic_clean.loc[:, 'pco2_scale'] = (df_analytic_clean['pco2_after_NIPPV'] - df_analytic_clean['pco2_after_NIPPV'].mean()) / 10\n",
    "df_analytic_clean.loc[:, 'ph_scale'] = (df_analytic_clean['ph_after_NIPPV'] - df_analytic_clean['ph_after_NIPPV'].mean()) / 0.1\n",
    "df_analytic_clean.loc[:, 'rr_scale'] = (df_analytic_clean['respiratory_rate_after_NIPPV'] - df_analytic_clean['respiratory_rate_after_NIPPV'].mean()) / 5\n",
    "df_analytic_clean.loc[:, 'hr_scale'] = (df_analytic_clean['heart_rate_after_NIPPV'] - df_analytic_clean['heart_rate_after_NIPPV'].mean()) / 10\n",
    "\n",
    "# Binary variables\n",
    "df_analytic_clean.loc[:, 'female'] = (df_analytic_clean['sex_category'] == 'Female').astype(int)\n",
    "\n",
    "df_analytic_clean.loc[:, 'fio2_high'] = (\n",
    "    df_analytic_clean['fio2_after_NIPPV'] > 0.40\n",
    ").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final df to CSV\n",
    "df_analytic_clean.to_csv('../output/NIPPV_analytic_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of rows\n",
    "total_rows = len(df_analytic_clean)\n",
    "\n",
    "# Total number of failures (failure == 1)\n",
    "total_failures = df_analytic_clean['failure'].sum()\n",
    "imv_failures = df_analytic_clean['failure_imv'].sum()\n",
    "death_failures = df_analytic_clean['failure_death'].sum()\n",
    "both_failures = df_analytic_clean[(df_analytic_clean['failure_imv'] == 1) & (df_analytic_clean['failure_death'] == 1)]['hospitalization_id'].nunique()\n",
    "\n",
    "#Print total patients and failures\n",
    "print(f'Total Patients: {total_rows}')\n",
    "consort[\"patients_post_missing\"] = total_rows\n",
    "print(f'Total failures: {total_failures}')\n",
    "consort[\"failures_post_missing\"] = total_failures\n",
    "print(f'Total IMV failures: {imv_failures - both_failures}')\n",
    "consort[\"imv_fail_post_missing\"] = imv_failures - both_failures\n",
    "print(f'Total death failures: {death_failures - both_failures}')\n",
    "consort[\"death_fail_post_missing\"] = death_failures - both_failures\n",
    "print(f'Both failures: {both_failures}')\n",
    "consort[\"both_fail_post_missing\"] = both_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export consort data to CSV\n",
    "pd.DataFrame([consort]).to_csv('../output_to_share/consort.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
